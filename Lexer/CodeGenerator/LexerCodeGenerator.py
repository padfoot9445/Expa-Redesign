import json
#forego constants file for just storing in json and python
with open(r"D:\coding\c#\Expa V4\Expa-Redesign\Lexer\CodeGenerator\Configs\NamespaceNames.json", "r") as namespace_names:
    namespace_names_dict:dict[str,str] = json.load(namespace_names)
with open(r"D:\coding\c#\Expa V4\Expa-Redesign\Lexer\CodeGenerator\Configs\ClassNames.json", "r") as class_names:
    class_names_dict: dict[str,str] = json.load(class_names)
with open(r"D:\coding\c#\Expa V4\Expa-Redesign\Lexer\CodeGenerator\Configs\Keywords.json", "r") as keywords:
    keywords_dict: dict[str,dict[str, str | list[int]]] = json.load(keywords)
with open(r"D:\coding\c#\Expa V4\Expa-Redesign\Lexer\CodeGenerator\Configs\Exceptions.json", "r") as exceptions:
    exceptions_dict: dict[str, list[str]] = json.load(exceptions)
    
def value_dict_to_TokenType_accessor(value:dict[str, str | list[int]]):
    return f"{class_names_dict["TokenTypes"]}.{value["name"].upper()}"
LexerFile: str = (
f"""
namespace {namespace_names_dict["Lexer"]};
using {namespace_names_dict["Tokens"]};
using {namespace_names_dict["TokenTypes"]};
using {namespace_names_dict["Exceptions"]};

internal partial class {class_names_dict["Lexer"]} : {f'I{class_names_dict["Lexer"]}'}
{{
    #region
    public List<{class_names_dict["Token"]}> Lex()
    {{
        //current points to the one we are currently processing(and therefore have not yet processed)
        while(Current < Code.Length)
        {{
            Start = Current;
            switch(Code[Current])
            {{
            {
                "".join(
                f"""
                case '{key.upper()}':
                    LexRV.Add(new({value_dict_to_TokenType_accessor(value)}, \"{key}\", Line ));
                    Current++;
                    break;
                """ for key, value in keywords_dict.items() if len(key) == 1
                )
                    #TODO: Add default(support for numbers and strings)
            } 
                default: ProcessDefaultFunctions(); break;

            }}
        }}
        return LexRV;
    }}
    #endregion
}}
"""
)



TTFile: str = (
f"""
namespace {namespace_names_dict['TokenTypes']};
enum {class_names_dict['TokenTypes']}
{{
    {
        ",\n\t".join(
            i["name"].upper() 
            for i in keywords_dict.values() 
            if not i["name"].startswith("Interpreter")
        )
    }
}}
"""
)


ExceptionsFile: str = (
f"""
namespace Exceptions;
{
    "\n".join(
        f"class {k} : {', '.join(e for e in v )} \n{{\n\tprivate const string Name = \"{k}\"; \n\tpublic {k}(string message, int line) : base(message, line, Name){{ }}\n\tprivate protected {k}(string message, int line, string childName): base(message, line, childName){{ }}\n}}" for k, v in exceptions_dict.items()
    )
}
"""
)
for fp, var in [("Lexer\AutoGenerated\Auto.Lexer.cs", LexerFile), ("Lexer\AutoGenerated\Auto.TokenTypes.cs", TTFile), ("Lexer\AutoGenerated\Auto.Exceptions.cs", ExceptionsFile)]:
    with open(fp, "w") as f:
        f.write(var)

print(1)
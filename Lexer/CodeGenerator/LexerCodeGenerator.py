import json
import enum
def Extract_Meta_Types(string: str) -> list[int]:
    return string.split(".")
#forego constants file for just storing in json and python
#TODO: Extra processing step to handle multi-character symbols
with open(r"Lexer/CodeGenerator/Configs/NamespaceNames.json", "r") as namespace_names:
    namespace_names_dict:dict[str,str] = json.load(namespace_names)
with open(r"Lexer/CodeGenerator/Configs/ClassNames.json", "r") as class_names:
    class_names_dict: dict[str,str] = json.load(class_names)
with open(r"Lexer/CodeGenerator/Configs/Keywords.json", "r") as keywords:
    keywords_dict: dict[str,dict[str, str | list[int]]] = json.load(keywords)
with open(r"Lexer/CodeGenerator/Configs/Exceptions.json", "r") as exceptions:
    exceptions_dict: dict[str, list[str]] = json.load(exceptions)
with open(r"Lexer/CodeGenerator/Configs/NumbersToMetaType.json", "r") as metatypes:
    metatypes_dict: dict[str, str] = json.load(metatypes)
def value_dict_to_TokenType_accessor(value:dict[str, str | list[int]]):
    return f"{class_names_dict['TokenTypes']}.{value['name'].upper()}"
LexerFile: str = (
f"""
namespace {namespace_names_dict["Lexer"]};
using {namespace_names_dict["Tokens"]};
using {namespace_names_dict["TokenTypes"]};
using {namespace_names_dict["Exceptions"]};

internal partial class {class_names_dict["Lexer"]} : {f'I{class_names_dict["Lexer"]}'}
{{
    #region
    private List<{class_names_dict["Token"]}> FirstPass()
    {{
        //current points to the one we are currently processing(and therefore have not yet processed)
        while(Current < Code.Length)
        {{
            Start = Current;
            switch(Code[Current])
            {{
            {
                "".join(
                f"""
                case '{key.upper()}':
                    LexRV.Add(new({value_dict_to_TokenType_accessor(value)}, \"{key}\", Line ));
                    Current++;
                    break;
                """ for key, value in keywords_dict.items() if len(key) == 1
                )
                    #TODO: Add default(support for numbers and strings)
            } 
                default: ProcessDefaultFunctions(); break;

            }}
        }}
        return LexRV;
    }}
    #endregion
}}
"""
)



TTFile: str = (
f"""
namespace {namespace_names_dict['TokenTypes']};
enum {class_names_dict['TokenTypes']}
{{
    {
        ",\n\t".join(
            i["name"].upper() 
            for i in keywords_dict.values() 
            if not i["name"].startswith("Interpreter")
        )
    }
}}
"""
)


ExceptionsFile: str = (
f"""
namespace Exceptions;
{
    "\n".join(
        f"class {k} : {', '.join(e for e in v )} \n{{\n\tprivate const string Name = \"{k}\"; \n\tpublic {k}(string message, int line) : base(message, line, Name){{ }}\n\tprivate protected {k}(string message, int line, string childName): base(message, line, childName){{ }}\n}}" for k, v in exceptions_dict.items()
    )
}
"""
)
#region metaTypeFile
metatype_assembling_dict: dict[str, list[str]] = {}
for value in metatypes_dict.values():
    if not value in metatype_assembling_dict.keys():
        metatype_assembling_dict[value] = []

for v in keywords_dict.values():
    split_list = [i.split(".") for i in v["types"]]
    for x in range(len(split_list)):
        temp = split_list[0: x+1]
        for i in metatypes_dict[".".join(i for )]
    for i in (metatypes_dict[".".join(i for i in split_list[0:x+1])] for x in range(len(split_list))):
        metatype_assembling_dict[i].append(v)
MetaTypeFile: str = (
f"""
namespace Tokens.Metatypes;
public static class IsMetaType
{"\n".join(f"private static readonly HashSet<TokenType> {k} = new(){{{",".join(i for i in metatype_assembling_dict[k])}}}; \n public static bool Is{k}(this Tokentype tt) => k.Contains(tt);" for k in metatype_assembling_dict.keys())}
"""
)
#endregion
for fp, var in [("Lexer\AutoGenerated\Auto.Lexer.cs", LexerFile), ("Lexer\AutoGenerated\Auto.TokenTypes.cs", TTFile), ("Lexer\AutoGenerated\Auto.Exceptions.cs", ExceptionsFile)]:
    with open(fp, "w") as f:
        f.write(var)

print(1)